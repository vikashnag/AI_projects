# -*- coding: utf-8 -*-
"""Public Relations case study.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BYu7OQDmrk9ZFUGk6EoBvEAkkTWgaUGJ
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

from wordcloud import WordCloud
import string
import nltk
from sklearn.feature_extraction.text import CountVectorizer

from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression

from sklearn.model_selection import train_test_split

from sklearn.metrics import confusion_matrix, classification_report

reviews_df= pd.read_csv('amazon_alexa.tsv', sep= '\t')
reviews_df.head()

reviews_df.info()

reviews_df.describe()

"""The mean of 4.4 of rating column indicates that most of the data has positive reviews."""

sns.heatmap(reviews_df.isnull(), yticklabels= False, cbar= False , cmap= 'Blues')

reviews_df.hist(bins= 30, color='b')

"""It is clear that most of the reviews are positive."""

reviews_df['length']= reviews_df['verified_reviews'].apply(len)
reviews_df.head()

reviews_df['length'].plot(bins= 100, kind= 'hist')

"""Most of the reviews are short in length."""

reviews_df['length'].describe()

# Shortest review in the data
reviews_df[reviews_df['length'] == 1]['verified_reviews'].iloc[0]

# Longest review in the data
reviews_df[reviews_df['length'] == 2851]['verified_reviews'].iloc[0]

# Average review length in the data
reviews_df[reviews_df['length'] == 132]['verified_reviews'].iloc[0]

positive= reviews_df[reviews_df['feedback'] == 1]
positive

negative= reviews_df[reviews_df['feedback'] == 0]
negative

sns.countplot(x= 'feedback', data= reviews_df)

sns.countplot(x= 'rating', data= reviews_df)

plt.figure(figsize= (25, 10))
sns.barplot(x= 'variation', y= 'rating', data= reviews_df)

sentences= reviews_df['verified_reviews'].tolist()
sentences

sentence_as_one_string= " ".join(sentences)
sentence_as_one_string

plt.figure(figsize= (20, 15))
plt.imshow(WordCloud().generate(sentence_as_one_string))

negative_sentences= negative['verified_reviews'].tolist()
negative_sentences

negative_as_one= " ".join(negative_sentences)
negative_as_one

plt.figure(figsize= (20, 15))
plt.imshow(WordCloud().generate(negative_as_one))

reviews_df.drop(['date', 'rating', 'length'], axis= 1, inplace= True)
reviews_df

variation_dummies= pd.get_dummies(reviews_df['variation'], drop_first= True)

reviews_df.drop('variation', axis= 1, inplace= True)

reviews_df= pd.concat([reviews_df, variation_dummies], axis= 1)
reviews_df

punct_removed= [char for char in sentence_as_one_string if char not in string.punctuation]
punct_removed

sent_join= ''.join(punct_removed)
sent_join

nltk.download('stopwords')

from nltk.corpus import stopwords

stopwords_removed= [ words for words in sent_join.split() if words.lower() not in stopwords.words('english')]
stopwords_removed

vectorizer= CountVectorizer()
X= vectorizer.fit_transform(stopwords_removed)
print(X.toarray())

def text_cleaning(text):
  punct_removed= [char for char in text if char not in string.punctuation]
  sent_join= ''.join(punct_removed)
  stopwords_removed= [ words for words in sent_join.split() if words.lower() not in stopwords.words('english')]
  return stopwords_removed

vectorizer= CountVectorizer(analyzer= text_cleaning)
reviews_cv= vectorizer.fit_transform(reviews_df['verified_reviews'])
print(reviews_cv.toarray())

reviews_cv.shape

reviews_df.drop(['verified_reviews'], axis= 1, inplace= True)

reviews= pd.DataFrame(reviews_cv.toarray())
reviews

reviews_df= pd.concat([reviews_df, reviews], axis= 1)
reviews_df

X= reviews_df.drop('feedback', axis= 1)
y= reviews_df['feedback']

X.shape, y.shape

X_train, X_test, y_train, y_test= train_test_split(X, y, test_size= 0.2)

nb_classifier= MultinomialNB()
nb_classifier.fit(X_train, y_train)

y_predict_train= nb_classifier.predict(X_train)

cm= confusion_matrix( y_train, y_predict_train)
sns.heatmap(cm, annot= True, fmt='d')

y_predict_test= nb_classifier.predict(X_test)

cm= confusion_matrix( y_test, y_predict_test)
sns.heatmap(cm, annot= True, fmt='d')

print( classification_report(y_test, y_predict_test ))

lr= LogisticRegression()
lr.fit(X_train, y_train)
lr_predict_train= lr.predict(X_train)

cm= confusion_matrix(y_train, lr_predict_train )
sns.heatmap(cm, annot= True, fmt= 'd')

print(classification_report(y_train, lr_predict_train))

lr_predict_test= lr.predict(X_test)

cm= confusion_matrix(y_test, lr_predict_test )
sns.heatmap(cm, annot= True, fmt= 'd')

print(classification_report(y_test, lr_predict_test))

